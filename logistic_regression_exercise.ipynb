{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pydataset import data\n",
    "\n",
    "from acquire import get_titanic_data\n",
    "from prepare import titanic_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquire Stage\n",
    "df = get_titanic_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>is_female</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass   age  sibsp  parch     fare  alone  is_female  \\\n",
       "0         0       3  22.0      1      0   7.2500      0      False   \n",
       "1         1       1  38.0      1      0  71.2833      0       True   \n",
       "2         1       3  26.0      0      0   7.9250      1       True   \n",
       "\n",
       "   embark_town_Queenstown  embark_town_Southampton  \n",
       "0                       0                        1  \n",
       "1                       0                        0  \n",
       "2                       0                        1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handle missing ages\n",
    "avg_age = df.age.mean()\n",
    "df.age = df.age.fillna(avg_age)\n",
    "\n",
    "# Encode the gender column\n",
    "df[\"is_female\"] = (df.sex == \"female\")\n",
    "\n",
    "# Encode the embarked_town\n",
    "# Embark_Town values are Southampton, Cherbourg, and Queenstown\n",
    "dummy_df = pd.get_dummies(df[['embark_town']], dummy_na=False, drop_first=True)\n",
    "df = pd.concat([df, dummy_df], axis=1)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df = df.drop(columns=[\"passenger_id\", \"deck\", \"class\", \"embarked\", \"sex\", \"embark_town\"])\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived                   0\n",
       "pclass                     0\n",
       "age                        0\n",
       "sibsp                      0\n",
       "parch                      0\n",
       "fare                       0\n",
       "alone                      0\n",
       "is_female                  0\n",
       "embark_town_Queenstown     0\n",
       "embark_town_Southampton    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double check to make sure we don't have any nulls\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the datasets\n",
    "train, validate, test = titanic_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate out our X and y values\n",
    "X_train = train.drop(columns=[\"survived\"])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=[\"survived\"])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=[\"survived\"])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **insert Exploratory Data Analysis here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    307\n",
       "1    191\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The most frequenly observed outcome will be our baseline\n",
    "train.survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.616"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_accuracy = (train.survived == 0).mean()\n",
    "round(baseline_accuracy, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "- Create a model using age, fare, and pclass\n",
    "- Does this model beat the baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline is 0.62\n",
      "Logistic Regression using age, pclass, and fare features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.70\n"
     ]
    }
   ],
   "source": [
    "# Create the logistic regression\n",
    "logit = LogisticRegression(random_state=123)\n",
    "\n",
    "# specify the features we're using\n",
    "features = [\"age\", \"pclass\", \"fare\"]\n",
    "\n",
    "# Fit a model using only these specified features\n",
    "# logit.fit(X_train[[\"age\", \"pclass\", \"fare\"]], y_train)\n",
    "logit.fit(X_train[features], y_train)\n",
    "\n",
    "# Since we .fit on a subset, we .predict on that same subset of features\n",
    "y_pred = logit.predict(X_train[features])\n",
    "\n",
    "print(\"Baseline is\", round(baseline_accuracy, 2))\n",
    "print(\"Logistic Regression using age, pclass, and fare features\")\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train[features], y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Create a model using age, fare, pclass, and gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression using age, pclass, fare, and gender features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.81\n"
     ]
    }
   ],
   "source": [
    "# Create the logistic regression\n",
    "logit1 = LogisticRegression(random_state=123)\n",
    "\n",
    "# specify the features we're using\n",
    "features = [\"age\", \"pclass\", \"fare\", \"is_female\"]\n",
    "\n",
    "# Fit a model using only these specified features\n",
    "logit1.fit(X_train[features], y_train)\n",
    "\n",
    "y_pred = logit1.predict(X_train[features])\n",
    "\n",
    "print(\"Logistic Regression using age, pclass, fare, and gender features\")\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit1.score(X_train[features], y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "\n",
    "Try out other combinations of features and models.\n",
    "\n",
    "Models Created:\n",
    "- `logit2`, all Features, 0.82 accuracy\n",
    "- `logit3`, all features with class_weight=\"balanced\", .80 accuracy\n",
    "- `logit4`, only age, .62 accuracy\n",
    "- `logit5`, only pclass, .67 accuracy\n",
    "- `logit6`, C hyperparameter close to zero, .62 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained on all features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.82\n"
     ]
    }
   ],
   "source": [
    "# All features, all default hyperparameters\n",
    "logit2 = LogisticRegression(random_state=123)\n",
    "\n",
    "logit2.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logit2.predict(X_train)\n",
    "\n",
    "print(\"Model trained on all features\")\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit2.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Features and we're setting the class_weight hyperparameter\n",
      "Accuracy of Logistic Regression classifier on training set: 0.8\n"
     ]
    }
   ],
   "source": [
    "# All features, but we'll use the class_weights to hold the actual ratios`\n",
    "logit3 = LogisticRegression(random_state=123, class_weight='balanced')\n",
    "\n",
    "logit3.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logit3.predict(X_train)\n",
    "\n",
    "accuracy = logit3.score(X_train, y_train)\n",
    "\n",
    "print(\"All Features and we're setting the class_weight hyperparameter\")\n",
    "print(f'Accuracy of Logistic Regression classifier on training set: {accuracy:.2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Features and we're setting the class_weight hyperparameter\n",
      "Accuracy of Logistic Regression classifier on training set: 0.62\n"
     ]
    }
   ],
   "source": [
    "# Only Age \n",
    "features = [\"age\"]\n",
    "\n",
    "# All features, but we'll use the class_weights to hold the actual ratios\n",
    "logit4 = LogisticRegression(random_state=123)\n",
    "\n",
    "logit4.fit(X_train[features], y_train)\n",
    "\n",
    "y_pred = logit4.predict(X_train[features])\n",
    "\n",
    "accuracy = logit4.score(X_train[features], y_train)\n",
    "\n",
    "print(\"All Features and we're setting the class_weight hyperparameter\")\n",
    "print(f'Accuracy of Logistic Regression classifier on training set: {accuracy:.2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Features and we're setting the class_weight hyperparameter\n",
      "Accuracy of Logistic Regression classifier on training set: 0.67\n"
     ]
    }
   ],
   "source": [
    "# Only pclass\n",
    "features = [\"pclass\"]\n",
    "\n",
    "# All features, but we'll use the class_weights to hold the actual ratios\n",
    "logit5 = LogisticRegression(random_state=123)\n",
    "\n",
    "logit5.fit(X_train[features], y_train)\n",
    "\n",
    "y_pred = logit5.predict(X_train[features])\n",
    "accuracy = logit5.score(X_train[features], y_train)\n",
    "\n",
    "print(\"All Features and we're setting the class_weight hyperparameter\")\n",
    "print(f'Accuracy of Logistic Regression classifier on training set: {accuracy:.2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Features, C hyperparameter approaching 0\n",
      "Baseline is 0.62\n",
      "Accuracy of this Logistic Regression on training set: 0.62\n"
     ]
    }
   ],
   "source": [
    "# All Features, C=0\n",
    "# All features, but we'll use the class_weights to hold the actual ratios\n",
    "logit6 = LogisticRegression(random_state=123, C=0.00000000000000000001)\n",
    "\n",
    "logit6.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logit6.predict(X_train)\n",
    "accuracy = logit6.score(X_train, y_train)\n",
    "\n",
    "print(\"All Features, C hyperparameter approaching 0\")\n",
    "print(\"Baseline is\", round(baseline_accuracy, 2))\n",
    "print(f'Accuracy of this Logistic Regression on training set: {accuracy:.2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Let's Pick our Best Models and Evaluate on Validate!\n",
    "- `logit1` trained with `features = [\"age\", \"pclass\", \"fare\", \"is_female\"]` has .81 accuracy\n",
    "- `logit2` trained on all features, with all other hyperparameters defaulted, has .82 accuracy\n",
    "- `logit3` trained on all features with `class_weight='balanced'` has accuracy of .80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit1 model using age, pclass, fare, and is_female as the features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82       132\n",
      "           1       0.72      0.67      0.70        82\n",
      "\n",
      "    accuracy                           0.78       214\n",
      "   macro avg       0.76      0.76      0.76       214\n",
      "weighted avg       0.77      0.78      0.77       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's determine logit1's metrics on validate\n",
    "features = [\"age\", \"pclass\", \"fare\", \"is_female\"]\n",
    "\n",
    "y_pred = logit1.predict(X_validate[features])\n",
    "\n",
    "print('Logit1 model using age, pclass, fare, and is_female as the features')\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit2 model using all features and all model defaults\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.82       132\n",
      "           1       0.74      0.65      0.69        82\n",
      "\n",
      "    accuracy                           0.78       214\n",
      "   macro avg       0.77      0.75      0.76       214\n",
      "weighted avg       0.77      0.78      0.77       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logit2 uses all features\n",
    "y_pred = logit2.predict(X_validate)\n",
    "\n",
    "print(\"Logit2 model using all features and all model defaults\")\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit3 model using all features, class_weight='balanced', and all other hyperparameters as default\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82       132\n",
      "           1       0.70      0.72      0.71        82\n",
      "\n",
      "    accuracy                           0.78       214\n",
      "   macro avg       0.76      0.77      0.76       214\n",
      "weighted avg       0.78      0.78      0.78       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logit3 uses all features and class_weight='balanced'\n",
    "y_pred = logit3.predict(X_validate)\n",
    "\n",
    "print(\"Logit3 model using all features, class_weight='balanced', and all other hyperparameters as default\")\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What next?\n",
    "- Consider the precision and recall values from each model. \n",
    "- Experiment with more hyperparameter values and combinations\n",
    "- Handle the age nulls differently\n",
    "    - We could try filling the nulls with median age instead of average age\n",
    "    - We could drop the nulls if they weren't such a large proportion of the dataset\n",
    "- Feature engineering\n",
    "- Handling outliers\n",
    "- Scaling (we'll do this later)\n",
    "\n",
    "Once we have a single model doing really well on `validate`, then we'll select that model to evaluate on `test`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow\n",
    "- Make a model, see if beats baseline\n",
    "- If it does, make a whole bunch o' models w/ different features, feature engineering, hyperparameters\n",
    "- Cherry pick our best 3-5 models based on their performance on `train` data\n",
    "- Evaluate those best candidates on `validate`\n",
    "- Keep on tuning hyperparameters and feature engineering to try to optimize performance on `validate`\n",
    "- But... if we're cherry picking things based on `validate`, it means we're overfitting to `validate`.\n",
    "- So our `test` dataset is our way of keeping ourselves honest\n",
    "- Once we have a \"best\" model for `validate`, we'll evaluate that model on `test`\n",
    "- We'll only \"look at\" `test` once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
